# Elasticsearch basic

다음과 같은 것들을 정리했다. 
- 엘라스틱 서치를 배우기 위해 먼저 알아야하는 사전 지식들 위주로 정리 (용어와 개념 등)
- 키바나에서 어떻게 학습 테스트를 해볼 수 있는지 위주로.
- Index 와 Document 개념에 대해서
- Document 의 CRUD 에 대해서
- 인덱스 매핑에 대해서 
- 인덱스 템플릿에 대해서
- Elasticsearch 에 사용하는 Analyzer 에 대해서 

*** 

## 엘라스틱 서치 요청과 응답

엘라스틱 서치는 요청과 응답을 모두 REST API 를 통해서 제공해준다.

REST API 는 리소스를 접근에 대해서 일정한 규칙을 정한 것이다. 

여기서는 키바나 Dev Tools 에 있는 콘솔을 이용해서 REST API 를 호출하면서 테스트를 해본다. 

### 시스템 상태 확인 

엘라스틱 서치에서늖 현재 상태를 확인할 수 있는 방법으로 `cat API` 를 사용하면 된다. 

cat API 에서는 Node, Shard, Template 등의 상태 정보나 통계 정보를 확인할 수 있다. 

cat API 를 통해서 클러스터 내부의 인덱스 목록을 확인하고 싶다면 `GET _cat/indice?v` API 를 호출하면 된다. 
- v 파라미터는 ㅋ라럼의 이름을 확인할 수 있고 이외에도 여러 파라미터가 있다. 

물론 키바나 웹페이지에서 클러스터의 내부 상태를 관리할 수 있지만 터미널 또는 API 를 직접 호출함을 통해서도 상태 체크가 가능하다. 

터미널에서는 `curl -X GET "localhost:9200/_cat/indices?v"` 를 호출하면 된다

## 인덱스와 도큐먼트 

엘라스틱 서치를 이해하기 위해서는 인덱스와 도큐먼트의 이해가 무척 중요하다. 

하나의 인덱스안에 여러 도큐먼트가 있는 구조이고

인덱스는 관계형 데이터베이스로 치면 테이블, 도큐먼트는 테이블 안에 있는 레코드라고 생각하면 편하다.

일반적으로 엘라스틱서치를 이용해서 시스템을 개발하면 하나의 프로젝트에 하나의 클러스터를 생성하고 클러스터 내부는 데이터 성격에 따라서 여러 개의 인덱스를 생성한다. 

### 도큐먼트 

도큐먼트는 엘라스틱 서치에서 기본으로 저장되는 단위로 JSON 형태이다.

엘라스틱 서치에 있는 개념들을 관계형 디비랑 비교하면 다음과 같다.

|MySQL|Elasticsearch|
|:---:|:---:|
|테이블 | 인덱스 |
|레코드 | 도큐먼트 |
|칼럼 | 필드 |
|스키마 | 매핑 |

__참고로 엘라스턱 7.x 버전에서는 type 이 존재했어서 관계형 디비와의 비교가 가능했는데 지금은 유효하지는 않다고한다.__

### 인덱스

하나의 인덱스에 다수의 도큐먼트가 포함되는 구조이다.

동일한 인덱스에 있는 도큐먼트는 동일한 스키마를 가진다. 

그리고 모든 도큐먼트는 하나의 인덱스에 포함되어야한다.

**스키마에 따른 그룹핑**
- 당연한 소리지만 인덱스는 스키마에 따라서 구분한다.
- 회원 스키마와 장바구니 스키마는 다를 것이므로 다른 인덱스로 하는게 낫다.
- 굳이 모든 요소를 포함하는 스키마를 세우는건 비효율적이다 라는 소리다.

**관리 목적의 그룹핑**
- 기본적으로 인덱스 하나에 무한개의 도큐먼트를 넣을 수 있다.
- 하지만 하나의 인덱스에 수억개의 도큐먼트가 포함된다면 성능이 나오진 않을 것이다.
- 그래서 엘라스틱 서치를 운영할 때 인덱스 용량 제한을 두게된다.
- 기본적으로는 도큐먼트 개수가 일정 개수를 넘어가거나 일정 용량을 넘어가게 되면 인덱스를 분리한다.
- 가장 기본적으로 사용하는 케이스는 날짜 별로 분리하는 것이다. 이렇게 하면 날짜별로 데이터가 분리될 것이다.
- 주로 월별로 인덱스를 분리한다.

## 도큐먼트 CRUD

도큐먼트를 엘라스틱서치에 저장하고 CRUD 하는 동작에 대해서 소개하곘다. 

인덱스 생성과 삭제 조회에 대해서 먼저 보자. 
- 인덱스 생성: `PUT index1 or POST index1`
- 인덱스 조회: `GET index1`
- 인덱스 삭제: `DELETE index1` 

인덱스를 삭제하면 인덱스 내부에 저장되어있는 도큐먼트는 모두 삭제된다. 

### 도큐먼트 생성 

엘라스틱서치에서 도큐먼트를 인덱스에 포함시키는 과정을 인덱싱 (Indexing) 이라고 부른다. 

인덱싱을 해보자.

```json
PUT index1/_doc/1
{
  "name": "mike",
  "age", 20,
  "gender": "male"
}
```
- 이렇게 호출하면 존재하지 않았던 index1 이 생기고 동시에 인덱스1에 document 가 생긴다. 
- _doc 는 엔드포인트 구분을 위한 예약어이고 숫자 1은 도큐먼트의 id 이다.
- 도큐먼트에는 age,name,gender 필드가 있고 각 필드에는 값이 있다.

이를 조회홰보자. `GET index1`

```json
{
  "index1": {
    "alias": {},
    "mappings": {
      "properties": {
        "age": { "type":  "long" ...},
        "gender": { "type":  "text", ...},
        "name": {"type": "text", ...}
      }
    },
    ...
  }
}
```
- index1 에서 생긴 필드들을 보면 age 는 long 타입, gender 와 name 은 모두 text 타입으로 **자동 생성** 되었다.
- 엘라스틱서치는 만들려는 도큐먼트의 필드를 보고 자동으로 스키마 즉 매핑을 생성하는데 이를 다아나믹 매핑이라고 부른다.
- 다이나믹 매핑은 이후에 자세히 설명하겠지만 추천하지는 않는다. 미리 어떤 타입이 올 지 알고있다면.

index1 에 새로운 필드를 가진 도큐먼트를 넣으면 어떻게 될까? 

데이터는 인덱스에 들어가게 되고 인덱스 mappings.properties 에 새로운 필드들이 추가된다. 

그리고 다른 예로 age 가 이미 숫자 필드로 등록되어 있는데 문자열로 데이터를 넘기면 어떻게 될까? 

이 경우에는 자동으로 타입변환이 된다.

엘라스틱서치의 대표적인 타입변환은 다음과 같다.
- 숫자 필드에 문자열이 입력되면 자동으로 숫자로 변환하려고 시도한다.
- 정수 필드에 소수가 입력되면 소수점 아래를 무시한다.

### 도큐먼트 읽기

이번에는 도큐먼트를 읽어보자. 

도큐먼트를 읽는 방법은 Id 로 조회하는 방법과 DSL (Domain Specific Language) 를 통해서 검색하는 방법이 있다. 

우선 도큐먼트 아이디를 사용해 조회하는 방법은 다음과 같다.

`GET index1/_doc/{id}`

하지만 실제로 빅데이터 세상에서는 도큐먼트를 하나씩 읽어오는 경우는 드물다. 다른 방법으로는 search 라는 DSL 쿼리를 통해서 도큐먼트를 읽어올 수 있다.

`GET index1/_search`

- _search DSL 쿼리를 사용하면 index1 에 있는 모든 도큐먼트를 가져온다.

### 도큐먼트 수정 

도큐먼트 수정을 할려면 `PUT index1/_doc/{id}` 하고 넣을 JSON 데이터를 전달하면 된다. 

사실 이건 덮어쓰기의 과정이다.

update API 를 하면 특정 도큐먼트의 값을 업데이트 할 수 있다.

```json
POST index1/_update/1
{
  "doc": {
    "name": "lee"
  }
}
```
- _update 라는 엔드포인트를 추가해서 특정 필드의 값만 업데이트 하는게 가능하다.
- 엘라스틱서치의 경우 도큐먼트 수정 비용이 비싼편이기 떄문에 추천하지는 않는다. 

### 도큐먼트 삭제

마지막으로 도큐먼트 삭제이다.

`DELETE index1/_doc/{id}` 를 하면 도큐먼트가 삭제된다.

*** 

## 응답 메시지

엘라스틱서치에서는 REST API 를 통해서 호출한다고 이전에 설명했었다.

이 경우 요청에 문제가 있거나 엘라스틱서치 서버에 문제가 있어서 성공적인 응답을 내리지 못할수도 있는데 이 경우의 상태 코드를 보자.

|코드|상태|해결방법
|:---:|:---:|:---:|
|200,201| 정상적으로 수행함| 
|4xx| 클라이언트 오류 | 클라이언트에서 문제를 해결해야함
|404| 요청한 리소스가 없음 | 인덱스나 도큐먼트가 존재하는지 체크|
|405| 요청 메소드 (POST, GET 등) 을 지원하지 않음| API 사용법 체크
|429| 요청 과부하 (Busy) | 재전송, 노드 추가 같은 조치 |
|5xx| 서버 오류| 엘라스틱서치 로그 확인 후 조치|

***

## 벌크 데이터 

데이터 CRUD 동작을 할 땐 REST API 를 호출해서 하나하나 도큐먼트를 요청하는 것보다 한번에 보내는게 더 나을 수 있다. 

엘라스틱서치에서는 이와 같은 bulk API 를 지원한다. 

bulk API 의 포맷은 다음과 같다.

```json
POST _bulk
{"index": {"_index":  "test", "_id": "1"}}
{"field1": "value1"}
{"create": {"_index": "test", "_id":"3"}}
{"field1": "value3"}
{"update": {"_id": "1", "_index": "test"}}
{"doc": {"field2": "value2"}}
{"delete": {"_index": "test", "_id": "2"}}
```
- bulk API 는 도큐먼트 읽기는 지원하지 않고 도큐먼트 생성/수정/삭제 만 지원한다.
- 포맷을 보면 알겠지만 삭제만 한 줄로 처리하고 나머지는 두 줄로 구성된다.
- 각 줄 사이에는 쉼표 등 별도의 구분자가 포함되지 않고 빈 줄을 허용하지 않는다.
- JSON 문법처럼 보이지만 복수의 JSON 구조를 줄바꿈 문자열로 구분하는 NDJSON (New-line Delimited JSON) 형태다.
- JSON 과 비슷하지만 문법이 조금 다르니 쉼표 사용에 주의하자

이 포맷에 맞춰서 index2 인덱스에 2 개의 도큐먼트를 벌크 형태로 넣어보자.

```json
POST _bulk
{"index":  {"_index": "index2", "_id": "4"}}
{"name": "park", "age":  30, "gender": "male"}
{"index":  {"_index": "index2", "_id": "5"}}
{"name": "jung", "age":  50, "gender": "male"}
```

이 요청을 터미널로 보낼려면 다음과 같이 보내면 된다.

`curl -H "Content-Type: application/x-ndjson -XPOST localhost:9200/_bulk --data-binary "@./bulk_index2"`

- curl 의 H 옵션은 헤더를 지칭한다.
- X 는 사용할 HTTP Method 를 나타내며 -XPOST 는 POST 방식으로 호출한단 뜻이다. 
- `_bulk` 는 bulk API 를 호출하는 것이다.
- `--data-binary` 는 POST 메소드에 우리가 전달할려는 파일을 바이너리 형태로 전송한단 뜻이다.
- 참고오 여기서 전달할려는 파일이 JSON 형식으로 되어있다면 오류가 발생한다. NDJSON 형태로 되어있어야 한다.

***

## 매핑

관계형 데이터베이스가 스키마 설정이 있는 것처럼 엘라스틱서치에서도 매팽 설정이라는 것이 있다. 

이는 JSON 형태의 데이터를 루씬이 이해할 수 있도록 바꿔주는 작업이다. 

엘라스틱서치가 전문검색과 대용량 데이터를 빠르게 실시간 검색이 가능한 이유가 매핑이 있기 때문이다. 

매핑을 사용자가 직접하면 명시적 매핑, 엘라스틱서치가 도와주면 다이나믹매핑이다. 

여기서는 이것들에 대해서 알아보자.  
- 매핑 설정 방법과 
- 좋은 매핑이 무엇인지
- 매핑할 때 사용하는 데이터 타입이 무엇인지 
- 특히 매핑에서 문자열 타입이 text 와 keyword 로 나눠지는데 이를 이해하는게 중요하다.

### 다이나믹 매핑

엘라스틱서치의 모든 인덱스는 매핑 정보를 가지고 있지만 유연함을 위해서 인덱스 생성시 매핑을 따로 정의하지 않아도 된다. 

따로 매핑하지 않아도 엘라스틱 서치가 자동적으로 매핑 정보를 생성해준다. 

엘라스틱서치의 다이나믹 매핑 기준은 다음과 같다.

|원본 소스 데이터 타입|다이나믹 매핑으로 변형된 데이터 타입|
|:---:|:---:|
|null| 필드를 추가하지 않아도 됨|
|boolean| boolean|
|float|float|
|object|object|
|integer|long|
|string|string 형태에 따라 date, text 와 keyword 가 합쳐진 멀티필드|

다이나믹 매핑을 사용하면 스키마를 고려하지 않아도 되지만 그만큼 비효율이 발생한다.

일반 정수의 경우 long 타입인 8바이트로 인식이 되는데 만약에 내가 나이를 넣는다면 short 인 2바이트만해도 충분하다.

그 다음에 country 나 gender 와 같은 범주형 데이터는 keyword 타입으로만 저장하면 되는데 굳이 전문검색을 위한 text 타입을 이요하지 않아도 된다.

keyword 타입은 주로 집계, 정렬, 필터를 위해서 사용한다.

### 명시적 매핑

인덱스 매핑을 직접 지정하는 걸 명시적 매핑이라고 한다. 

인덱스를 생성할 때 mappings 정의를 설정하거나 mapping API 를 이용해서 매핑을 지정해줄 수 있다.

이런식으로 요청하면 된다. 

```json
PUT "인덱스명"
{
  "mappings": {
    "properties": {
      "필드명": "필드타입"
    }
  }
}
```

실제 예시는 다음과 같다.

```json
PUT "index3"
{
  "mappings": {
    "properties": {
      "age": {"type": "short"},
      "name": {"type":  "text"},
      "gender": {"type": "keyword"}
    }
  }
}
```

어떠한 타입의 데이터가 들어올 지 미리 아는 경우라면 이렇게 매핑을 지정해두는 편이 효율적이다.

그리고 알아둬야 할 지식으로 매핑을 선언해둔 필드는 수정하거나 삭제할 수 없다.

그러므로 필드 이름을 변경하거나 데이터 타입을 변경할려면 새로운 인덱스를 만들어야 한다.
- version 을 인덱스에 붙여야 하나 싶다.

아니면 reindex API 를 사용하는 방법도 있긴하다. 

마지막으로 매핑에서 다루는 파라미터들도 알아두면 좋다. properties 파라미터외에 analyzer, format 등도 있다. 이건 온라인 레퍼런스를 찾아보자.

### 매핑 타입

명시적 매핑을 사용하기 위해서는 엘라스틱 서치가 지원하는 데이터 타입에 대한 이해가 필요하다.

물론 지금 나와있는 타입 외에도 다양한 데이터 타입이 있다.

버전에 따라 타입은 계속 추가/삭제/수정 되는데 지금은 기본적인 데이터 타입만 이해하자.

|데이터 상태|데이터 타입|설명|
|:---:|:---:|:---:|
|텍스트| text| 전문검색이 필요한 데이터로 텍스트 분석기가 텍스트를 작은 단위로 분리한다.|
|텍스트| keyword| 정렬이나 집계에 사용되는 텍스트 데이터로 분석을 하지 않고 원문을 통째로 저장한다.|
|날짜| date| 날짜/시간 데이터|
|정수| byte,short,integer,long|byte: 부호 있는 8비트, short: 부호 있는 16비트, integer: 부호있는 32비트, long: 부호있는 64비트|
|실수| scaled_float,half_float,double,float| scaled_float: float 데이터에 특정 숫자를 곱해서 정수형으로 만든 데이터 타입. 정확도는 떨어지나 필요에 따라 집계 등에서 효율적임, half_float: 16비트 부동소수점 실수 데이터, float: 32비트 부동 소수점 실수 데이터, double: 부동 소수점 64비트 실수 데이터
|불린| boolean| true/false|
|IP 주소| ip| ipv4, ipv6 타입 IP 주소를 입력|
|위치정보| geo-point, geo-shape|geo-point: 위도, 경도 값을 갖는다. geo-shape: 하나의 위치 포인트가 아닌 임의의 지형을 갖는다.|
|범위 값| integer_range, long_range, float_range, double_range, ip_range, date_range| 범위를 설정할 수 있는 데이터로 최소값과 최대값을 넣으면 된다.|
|객체형|object|계층 구조를 가지는 형태로 필드 안에 다른 필드들이 들어가있는 데이터를 말한다.|
|배열형|nested|배열형 객체를 저장한다. 객체를 따로 인덱싱해서 객체가 하나로 합쳐지는 것을 말고 배열 내부의 객체에 쿼리로 접근할 수 있다.|
|배열형|join|부모/자식 관계를 표현할 수 있다.|

### 멀티 필드를 활용한 문자열 처리 

엘라스틱서치 5.x 버전부터 문자열 타입이 text 타입과 keyword 타입으로 구별되었다.

이 두가지 타입이 어떻게 사용되는지 알아보고 멀티 필드를 이용해 같이 사용하는 방법도 알아보자.

#### 텍스트 타입

엘라스틱서치에서 텍스트 타입은 일반적으로 문장을 저장하는 매핑 타입으로 사용한다.

예로 다음 문장은 텍스트 타입으로 저장하는게 좋다.

```
We offer solutions for enterprise search, observability, and security that are built on a single, flexible technology stack that can be deployed anywhere
```

텍스트 타입으로 지정된 문자열은 Analyzer 에 의해 Token 으로 분석된다. 이렇게 만들어진 Token 은 필터 작업을 거쳐서 인덱싱 되고 이를 역인덱싱 (Inverted Indexing) 이라고 부른다.

이때 역인덱스에 저장된 토큰을 용어 (Term) 이라고 부른다. 

즉 위의 예시는 가장 기본적인 Analyzer 에 의해서 분석된다면 다음과 같이 토큰이 분리되어 인덱싱 된다.

```json
we
offer 
solutions
for
enterprise
...
```

그리고 다음과 같은 전문검색을 도와주는 DSL 을 이용하면 검색이 가능하다.

```json
GET text_index/_search
{
  "query": {
    "match": {
      "contents": "offer"
    }
  }
}
```

- 여기서는 contents 필드에 위의 문장이 들어가있다고 가정했다.
- match 는 전문검색을 할 수 있는 쿼리이다.
- 텍스트 타입은 기본적으로 집계나 정렬을 할 수 없다. 매핑 파라미터를 통해서는 가능하다. 대신 이것도 메모리를 많이 쓴다.

#### 키워드 타입

키워드 타입은 카테고리나 사람 이름, 브랜드 등 규칙성이 있거나 유의미한 값들의 집합 즉 범주형 데이터에 기본적으로 사용된다.

그리고 키워드 타입은 텍스트 타입과 다르게 분석기를 거치지 않고 문자열 전체가 하나의 용어로 인덱싱 된다.

텍스트 타입과 비교해보자.

```
beautiful day
``` 

라는 문자열을 저장한다고 하면 키워드 타입은 "beautiful day" 그대로 저장되는 반면에  

텍스트 타입은 "beautiful" 과 "day" 나눠서 저장한다.

따라서 키워드 타입은 전문 검색은 어렵지만 집계나 정렬 그리고 완전 일치 검색은 사용할 수 있다.

#### 멀티 필드

멀티 필드는 단일 필드 입력에 대해서 여러 하위 필드를 정의하는 기능이다. 

이를 위해 fields 는 하나의 필드를 여러 용도로 사용할 수 있게 만들어준다. 

문자열의 경우 전문 검색이 필요하면서 정렬도 필요하다고 판단이 되면 텍스트 필드와 키워드 필드 모두 같이 쓰도록 하면 된다.

또 처음에는 키워드 타입을 쓰고 있다가 전문 검색 기능이 필요해지면서 텍스트 필드를 추가할 수도 있다.

contents 필드를 텍스트 타입과 키워드 타입으로 동시에 사용하는 방법을 한번 알아보자.

```json
PUT modified_index
{
  "mappings": {
    "properties": {
      "contents": {
        "type": "text",
        "fields": {
          "keyword": {"type": "keyword"}
        }
      }
    }
  }
}
```
- 여기서 contents 타입은 텍스트 타입이면서 키워드 타입을 가진다.

## 인덱스 템플릿 

인덱스 템플릿은 주로 설정이 돌일한 복수의 인덱스를 만들 때 사용한다.

주로 관리를 하기 쉽게 만들기 위해서, 성능을 위해서 인덱스를 파티셔닝 하는 경우가 많은데 이 때 파티셔닝 되는 인덱스들은 구조가 같아야한다.

그래서 인덱스 템플릿을 사용한다. 매번 복사해서 사용하는 방식은 비효율적이므로.

### 템플릿 확인

템플릿 API 를 통해서 인덱스 템플릿을 볼 수 있다.

다음은 전체 인덱스 템플릿을 보는 방식이다.

```json
GET _index_template
```

물론 특정 인덱스 템플릿을 확인하는 것도 가능하다.

```json
GET _index_template/{templtae_name}
```

### 텔플릿 설정

인덱스 템플릿을 생성할 때 다양한 설정을 할 수 있지만 일반적으로는 매핑 (mapping) 과 세팅 (setting) 설정을 많이한다.

인덱스 템플릿 기술을 이용해서 인덱스 매핑과 세팅을 효율적으로 사용해보자.

#### 템플릿 생성

다음과 같은 입력을 하면 템플릿을 생성할 수 있다. 

```json
PUT _index_template/test_template
{
  "index_patterns": ["test_*"],
  "priority": 1,
  "template": {
    "settings": {
      "number_of_shards": 3,
      "number_of_replicase": 1
    },
    "mappings": {
      "properties": {
        "name": {"type": "text"},
        "age": {"type": "short"},
        "gender": {"type": "keyword"}
      }
    }
  }
}
```

- 템플릿의 이름은 "test_template" 이다.
- index_pattern 은 인덱스가 만들어질 때 이 index_pattern 과 비교해서 매칭이 되면 이 템플릿으로 세팅한다는 뜻이다.
- priority 는 index_pattern 에 의해서 여러개가 매칭될 경우 priority 값이 높은 템플릿으로 세팅된다는 값이다.

이렇게 만들었는데 도큐먼트의 매핑 타입과 인덱스의 매핑 타입이 다르면 400 번 에러가 발생한다. 

### 다이나믹 템플릿

다이나믹 템플릿은 매핑을 다이나믹하게 지정하는 템플릿 기술이다.

왜 다이나믹한 기술이 필요할까?

매핑은 저장과 검색의 근간이 되는 기술이라서 신중해야 하는데

다이나믹 템플릿이 필요한 경우는 로그와 같은 비정형화된 데이터를 저장할 때 필요하다.

우리는 로그의 모든 구조를 파악하지 못할 수 있다. 

다이나믹 템플릿은 이처럼 매핑을 정확하게 정할 수 없기 때문에 대략적인 데이터 구조만 알고 있을 때 사용할 수 있는 기술이다.

다음은 인덱스를 만들 때 다이나믹 템플릿을 적용한 경우다. 

```json
PUT dynamic_index1
{
  "mappings": {
    "dynamic_templates": [
      {
        "my_string_fields": {
          "match_mapping_type": "string",
          "mapping": {"type":  "keyword"}
        }
      }
    ]
  }
}
```
- dynamic_index1 는 다이나믹 템플릿을 사용한다.
- my_string_fields 는 저으이한 다이나믹 템플릿의 이름이다.
- match_mapping_type 은 이 템플릿이 발동할 트리거를 말하며 여기서는 문자열 타입의 데이터가 들어올 때 시작된다.
- 문자열 타입의 데이터가 들어오면 keyword 타입으로 매핑된다.

이외에도 match 나 unmatch 를 통해서 다이나믹 템플릿 적용을 할 지 말지를 결정할 수 있다. 

다음은 그 예시다. 

```json
PUT dynamic_index2
{
  "mappings": {
    "dynamic_templates": [
      {
        "my_string_fields": {
          "match": "long_*",
          "unmatch": "*_text",
          "mapping": {"type":  "keyword"}
        }
      }
    ]
  }
}
```
- 이 템플릿에 따르면 long_num 과 같은 필드가 오면 발동되지만 long_text 와 같은 필드가 오면 실행되지 않는다.

## 분석기 (Analyzer)

엘라스틱서치는 전문 검색을 지원하기 위해서 역인덱싱 기술을 지원한다.

역인덱싱 (Inverted indexing) 기술은 장문의 문자열을 쪼개서 인덱싱하고 이 인덱싱을 통해서 문서 (Document) 를 찾아내는 기술이다.

예로 한번 바로보자 

다음과 같은 Document 1 과 Document 2 가 있고 이를 역인덱싱한다고 생각해보자. 
```json
// Document 1
I love cute dog

// Document 2
the 10 most loving dog breeds
```

이는 이렇게 저장될 것이다.

|번호|단어|문서|
|:---:|:---:|:---:|
|1|10|2|
|2|breeds|2|
|3|cute|1|
|4|dog|1,2|
|5|i|1|
|6|love|1,2|
|7|most|2|

forward index 의 경우는 그 반대로 생각하면 된다. 각각의 문서당 인덱스를 저장하는 기술이다. 
- [Wikipedia - The forward index](https://en.wikipedia.org/wiki/Search_engine_indexing#The_forward_index) 에 따르면 forward index 는 inverted index 로 변환하기 전 중간 저장소를 위해서 주로 쓰이는 기술이라고 한다.
- inverted index 를 만들 때 걸리는 시간이 bottleneck 이 될 수 있어서 Asynchronous 하게 처리하기 위해서 forward index 를 만들고 이후에 inverted index 를 만드는 거라고 이해했다. 
- forward index 에서 inverted index 로의 변환은 sorting 의 문제이기 때문에.    

전문 검색에서 결과를 잘 얻기 위해서는 문자열을 잘 나누는게 중요하기 떄문에 

엘라스틱서치에서는 Analyzer 에서는 이를 지원하기 위해 3가지 구성요소로 나뉘었다.
- 캐릭터 필터 (Character Filter): 문자열을 전처리하는 컴포넌트로 주어진 문자열의 공백을 삭제하거나 특정한 문자열이 들어오면 삭제 또는 변경하는 작업을 한다.
- 토크나이저 (Tokenizer): Analyzer 에서 반드시 필요한 요소로 문자열을 Token 으로 쪼개는 역할을 한다. 하나의 Analyzer 는 하나의 Tokenizer 를 가진다. (뭐 당연하다.)
- 토큰 필터 (Token Filter): Token 들을 역인덱싱을 통해서 저장할지 말지, 저장한다면 어떻게 변환해서 저장할지를 관리하는 필터이다.
- 문자 처리 순서는 캐릭터 필터를 거친 후 토크나이저를 거친 토큰들이 토큰 필터를 거쳐서 인덱스에 저장된다.  

토큰 필터를 거쳐서 저장되는 Token 들은 역인덱스에 저장되며 이 단위들은 용어 (Term) 이라고 한다.

### 분석기 API

엘라스틱서치는 필터와 토크나이저를 테스트 해볼 수 있는 analyzer API 를 제공해준다.

이를 이전과 마찬가지로 REST API 형식으로 테스트 해볼 수 있는데 여기서는 간단하게만 살펴보겠다.

키바나 콘솔에서 다음과 같이 입력해보자.
```json
POST _analyze
{
  "analyzer": "stop",
  "test": "The 10 most loving dog breeds"
}
```
- 여기서는 stop 분석기를 이용했다. 
- stop 분석기는 lowercase 토큰 필터와 stop 토크나이저를 이용한다.

결과는 다음과 같다.

```json
{
  "tokens": [
    {"token":  "most", ...},
    {"token":  "loving", ...}
    {"token":  "dog", ...}
    ...
  ]
}
```

### 분석기 종류

엘라스틱서치는 다양한 분석기를 제공해준다. 

그리고 엘라스틱서치는 성장이 빠른 오픈소스라서 버전별로 분석기의 변화가 많다.

전체 분석기의 종류는 온라인 레퍼런스를 참고해보자.

사용방식이나 동작원리가 비슷하기 떄문에 하나만 이해해도 나머지 분석기를 이해하는데는 문제가 없다.

일단 자주 사용하는 분석기를 보자.

|분석기|설명|
|:---|:---|
|standard| 특별한 설정이 없으면 엘라스틱서치가 자동으로 사용하는 분석기다. 영문법을 기준으로하는 스탠다드 토크나이저와 소문자 변경 필터, 스톱 필터가 포함되어 있다|
|simple|문자만 토큰화 된다. 숫자나 하이픈(-), 작은 따옴표(') 같은 문자들은 토큰화 되지 않는다.|
|whitespace| 공백을 기준으로 토큰화 한다.|
|stop|| simple 분석기와 비슷하지만 거기에 stop 필터가 추가되었다.|

- Stop 필터는 특정한 단어들을 제거해줄 수 있는 필터다.

### 토크나이저 

이제는 대표적인 토크나이저를 한번 살펴보자.

토크나이저는 문자열을 분리해서 토큰화 하는 역할을 한다.

|토크나이저|설명|
|:---|:---|
|standard| 스탠다드 분석기가 사용하는 토크나이저로 특별한 설정이 없으면 사용하는 기본 토크나이저다. 쉼표(,) 나 점(.) 같은 기호를 제거해나가며 영문법을 기반으로 토큰을 분리해나간다.|
|lowercase| 텍스트 기반으로 토큰을 분리하며 분리한 토큰은 모두 소문자로 변경된다.|
|ngram| 원문으로부터 N 개의 연속된 글자들 모두를 토큰화 한다. 예로 "엘라스틱서치" 를 넣고 2gram 으로 하면 [엘라,라스,스틱,틱서,서치] 가 토큰화 된다. 가장 많은 경우의 수를 만들 수 있어서 검색에 강점이 있지만 Ngram 이므로 N 개 이하로는 검색이 불가능 하다는 단점도 있다. 그리고 모든 조합을 추출한다고 시간이 많이 걸리고 저장을 많이 한다.|
|uax_url_email| 스탠다느 토크나이저와 비슷하지만 이메일과 url 을 토큰화 하는데 강점이 있다.|

### 커스텀 분석기

커스텀 분석기는 엘라스틱서치에서 제공하는 내장 분석기 중 원하는 분석기가 없는 경우에 사용자가 이를 직접 토크나이저와 필터 등을 조합해서 만들어내는 분석기다.

예시로 필터들의 조합과 순서를 다르게 해서 직접 만들 수 있다.

다음 예는 인덱스를 만들 때 커스텀 분석기를 만들고 이를 사용하도록 하는 예시다.

```json
PUT custom_analyzer
{
  "settings": {
    "analysis": {
      "filter": {
        "my_stopwords": {
          "type": "stop",
          "stopwords": ["lions"]
        }
      },
      "analyzer": {
        "my_analyzer": {
          "type": "custom",
          "char_filter": [],
          "tokenizer": "standard",
          "filter": ["lowercase","my_stopwords"]
        }
      }
    }
  }
}
```
- analysis 밑에 filter 와 analyzer 를 새로 만들어서 사용하도록 했다.
- 새로 만든 필터는 lions 가 오면 이를 무시하도록 하는 필터다.
- 새로 만든 analyzer 는 standard 토크나이저를 사용했고 캐릭터 필터는 사용하지 않았다. 그리고 토큰 필터로는 lowercase 와 커스텀 필터를 사용하도록 했다.
- 적용되는 필터는 가장 앞에것부터 토큰에 적용된다고 생각하면 된다. 